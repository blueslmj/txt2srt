#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
éŸ³é¢‘-æ–‡æœ¬å¯¹é½å·¥å…· - WhisperX ç‰ˆæœ¬
ä½¿ç”¨ WhisperX çš„å¼ºåˆ¶å¯¹é½åŠŸèƒ½ï¼Œè·å¾—æ›´ç²¾ç¡®çš„æ—¶é—´æˆ³
"""

import os
import sys
import argparse
import re
from typing import List, Dict

# WhisperX ç›¸å…³å¯¼å…¥
import whisperx
import torch


def format_timestamp(seconds: float) -> str:
    """
    å°†ç§’æ•°è½¬æ¢ä¸ºSRTæ—¶é—´æˆ³æ ¼å¼ (HH:MM:SS,mmm)
    """
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    milliseconds = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"


def split_text_into_segments(text: str, max_chars: int = 30) -> List[str]:
    """
    å°†é•¿æ–‡æœ¬åˆ†å‰²æˆé€‚åˆå­—å¹•æ˜¾ç¤ºçš„çŸ­å¥
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        max_chars: æ¯æ®µæœ€å¤§å­—ç¬¦æ•°
    
    Returns:
        åˆ†å‰²åçš„æ–‡æœ¬æ®µè½åˆ—è¡¨
    """
    segments = []
    
    # æŒ‰æ¢è¡Œç¬¦åˆ†å‰²
    lines = text.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # æŒ‰ä¸»è¦æ ‡ç‚¹ç¬¦å·åˆ†å‰²
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿï¼›.!?;])', line)
        
        current_segment = ""
        
        for i in range(0, len(sentences), 2):
            sentence = sentences[i]
            punct = sentences[i + 1] if i + 1 < len(sentences) else ""
            
            if not sentence.strip():
                continue
            
            full_sentence = sentence + punct
            potential_segment = current_segment + full_sentence
            
            if len(potential_segment) <= max_chars:
                current_segment = potential_segment
            else:
                if current_segment:
                    segments.append(current_segment.strip())
                
                if len(full_sentence) <= max_chars:
                    current_segment = full_sentence
                else:
                    # å¥å­å¤ªé•¿ï¼ŒæŒ‰é€—å·åˆ†å‰²
                    sub_segments = _split_long_sentence(full_sentence, max_chars)
                    for sub in sub_segments[:-1]:
                        segments.append(sub.strip())
                    current_segment = sub_segments[-1] if sub_segments else ""
        
        if current_segment.strip():
            segments.append(current_segment.strip())
    
    return segments


def _split_long_sentence(sentence: str, max_chars: int) -> List[str]:
    """åˆ†å‰²è¶…é•¿å¥å­"""
    if len(sentence) <= max_chars:
        return [sentence]
    
    segments = []
    parts = re.split(r'([ï¼Œ,ã€])', sentence)
    
    current = ""
    for i in range(0, len(parts), 2):
        part = parts[i]
        comma = parts[i + 1] if i + 1 < len(parts) else ""
        
        if not part.strip():
            continue
        
        full_part = part + comma
        potential = current + full_part
        
        if len(potential) <= max_chars:
            current = potential
        else:
            if current:
                segments.append(current.strip())
            
            if len(full_part) > max_chars:
                # å¼ºåˆ¶æŒ‰å­—æ•°åˆ†å‰²
                while len(full_part) > max_chars:
                    segments.append(full_part[:max_chars].strip())
                    full_part = full_part[max_chars:].strip()
                current = full_part
            else:
                current = full_part
    
    if current.strip():
        segments.append(current.strip())
    
    return segments if segments else [sentence]


def align_audio_text_whisperx(
    audio_path: str, 
    text: str, 
    model_name: str = "base", 
    use_gpu: bool = True,
    max_chars: int = 30,
    language: str = "zh"
) -> List[Dict]:
    """
    ä½¿ç”¨ WhisperX è¿›è¡ŒéŸ³é¢‘-æ–‡æœ¬å¯¹é½
    
    WhisperX çš„ä¼˜åŠ¿ï¼š
    1. ä½¿ç”¨ wav2vec2 è¿›è¡Œå¼ºåˆ¶å¯¹é½ï¼Œç²¾åº¦æ›´é«˜
    2. ç›´æ¥åˆ†æéŸ³é¢‘æ³¢å½¢ï¼Œä¸å— Whisper è¯†åˆ«é”™è¯¯å½±å“
    3. å¯ä»¥è·å¾—è¯çº§ç”šè‡³éŸ³ç´ çº§æ—¶é—´æˆ³
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        text: ç”¨æˆ·æä¾›çš„å‡†ç¡®æ–‡æœ¬
        model_name: Whisperæ¨¡å‹å¤§å°
        use_gpu: æ˜¯å¦ä½¿ç”¨GPU
        max_chars: æ¯è¡Œæœ€å¤§å­—ç¬¦æ•°
        language: è¯­è¨€ä»£ç 
    
    Returns:
        åŒ…å«æ—¶é—´æˆ³çš„æ–‡æœ¬æ®µè½åˆ—è¡¨
    """
    # è®¾ç½®è®¾å¤‡
    device = "cuda" if use_gpu and torch.cuda.is_available() else "cpu"
    compute_type = "float16" if device == "cuda" else "int8"
    
    if device == "cuda":
        try:
            gpu_name = torch.cuda.get_device_name(0)
            print(f"âœ… ä½¿ç”¨è®¾å¤‡: CUDA ({gpu_name})")
        except:
            print(f"âœ… ä½¿ç”¨è®¾å¤‡: CUDA")
    else:
        print("âš ï¸ GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUå¤„ç†ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    
    print(f"\nğŸ¯ æ­¥éª¤1: åŠ è½½ WhisperX æ¨¡å‹ ({model_name})...")
    model = whisperx.load_model(model_name, device, compute_type=compute_type)
    
    print(f"ğŸ¯ æ­¥éª¤2: ä½¿ç”¨ Whisper è¿›è¡Œåˆæ­¥è¯†åˆ«...")
    audio = whisperx.load_audio(audio_path)
    result = model.transcribe(audio, batch_size=16, language=language)
    
    print(f"   è¯†åˆ«åˆ° {len(result['segments'])} ä¸ªè¯­éŸ³æ®µè½")
    
    print(f"\nğŸ¯ æ­¥éª¤3: åŠ è½½å¯¹é½æ¨¡å‹ (wav2vec2)...")
    # åŠ è½½å¯¹é½æ¨¡å‹
    model_a, metadata = whisperx.load_align_model(
        language_code=language, 
        device=device
    )
    
    print(f"ğŸ¯ æ­¥éª¤4: æ‰§è¡Œå¼ºåˆ¶å¯¹é½...")
    # æ‰§è¡Œå¯¹é½ - è¿™æ˜¯ WhisperX çš„æ ¸å¿ƒä¼˜åŠ¿
    result = whisperx.align(
        result["segments"], 
        model_a, 
        metadata, 
        audio, 
        device,
        return_char_alignments=True  # è·å–å­—ç¬¦çº§å¯¹é½
    )
    
    # æå–è¯çº§æ—¶é—´æˆ³
    word_segments = []
    for segment in result["segments"]:
        if "words" in segment:
            for word in segment["words"]:
                if "start" in word and "end" in word:
                    word_segments.append({
                        "word": word["word"],
                        "start": word["start"],
                        "end": word["end"]
                    })
    
    print(f"   è·å¾— {len(word_segments)} ä¸ªè¯çº§æ—¶é—´æˆ³")
    
    print(f"\nğŸ¯ æ­¥éª¤5: å°†ç”¨æˆ·æ–‡æœ¬æ˜ å°„åˆ°æ—¶é—´æˆ³...")
    
    # åˆ†å‰²ç”¨æˆ·æ–‡æœ¬
    user_sentences = split_text_into_segments(text, max_chars=max_chars)
    print(f"   ç”¨æˆ·æ–‡æœ¬æœ‰ {len(user_sentences)} ä¸ªå¥å­ï¼ˆæ¯è¡Œé™åˆ¶ {max_chars} å­—ï¼‰")
    
    # ä½¿ç”¨è¯çº§æ—¶é—´æˆ³ä¸ºç”¨æˆ·å¥å­åˆ†é…æ—¶é—´
    aligned_segments = align_user_sentences_to_words(user_sentences, word_segments)
    
    # åå¤„ç†ï¼šä¿®å¤é‡å 
    aligned_segments = fix_overlapping_timestamps(aligned_segments)
    
    print(f"\nâœ… å¯¹é½å®Œæˆï¼ç”Ÿæˆäº† {len(aligned_segments)} ä¸ªå­—å¹•æ®µè½")
    
    return aligned_segments


def align_user_sentences_to_words(
    user_sentences: List[str], 
    word_segments: List[Dict]
) -> List[Dict]:
    """
    å°†ç”¨æˆ·å¥å­ä¸ WhisperX çš„è¯çº§æ—¶é—´æˆ³å¯¹é½
    
    ç­–ç•¥ï¼šä½¿ç”¨å­—ç¬¦çº§åŒ¹é…ï¼Œæ‰¾åˆ°æ¯ä¸ªç”¨æˆ·å¥å­å¯¹åº”çš„æ—¶é—´èŒƒå›´
    """
    if not word_segments:
        print("âš ï¸ è­¦å‘Š: æ²¡æœ‰è¯çº§æ—¶é—´æˆ³ï¼Œä½¿ç”¨ä¼°ç®—")
        return []
    
    # æ„å»ºè¯†åˆ«æ–‡æœ¬çš„å­—ç¬¦-æ—¶é—´æ˜ å°„
    char_times = []
    for word in word_segments:
        word_text = word["word"]
        word_start = word["start"]
        word_end = word["end"]
        word_duration = word_end - word_start
        
        # ä¸ºæ¯ä¸ªå­—ç¬¦ä¼°ç®—æ—¶é—´
        for i, char in enumerate(word_text):
            if char.strip():  # è·³è¿‡ç©ºæ ¼
                char_time = word_start + (i / len(word_text)) * word_duration
                char_times.append({
                    "char": char,
                    "time": char_time
                })
    
    # æå–è¯†åˆ«çš„å­—ç¬¦åºåˆ—ï¼ˆå»é™¤æ ‡ç‚¹ï¼‰
    def remove_punct(text):
        return ''.join([c for c in text if c.strip() and c not in 'ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼šã€,.!?;: ã€€ã€Œã€ã€ã€""''ï¼ˆï¼‰()ã€ã€‘[]'])
    
    recognized_chars = [ct["char"] for ct in char_times if ct["char"] not in 'ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼šã€,.!?;: ã€€ã€Œã€ã€ã€""''ï¼ˆï¼‰()ã€ã€‘[]']
    recognized_times = [ct["time"] for ct in char_times if ct["char"] not in 'ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼šã€,.!?;: ã€€ã€Œã€ã€ã€""''ï¼ˆï¼‰()ã€ã€‘[]']
    
    # ä¸ºæ¯ä¸ªç”¨æˆ·å¥å­æ‰¾åˆ°å¯¹åº”çš„æ—¶é—´èŒƒå›´
    aligned_segments = []
    current_char_idx = 0
    
    for sentence in user_sentences:
        if not sentence.strip():
            continue
        
        sentence_chars = remove_punct(sentence)
        if not sentence_chars:
            continue
        
        # åœ¨è¯†åˆ«å­—ç¬¦ä¸­æŸ¥æ‰¾åŒ¹é…
        best_start_idx = current_char_idx
        best_end_idx = min(current_char_idx + len(sentence_chars), len(recognized_chars))
        
        # ç®€å•çš„æ»‘åŠ¨çª—å£åŒ¹é…
        best_match_score = 0
        search_range = min(50, len(recognized_chars) - current_char_idx)
        
        for offset in range(search_range):
            start_idx = current_char_idx + offset
            end_idx = min(start_idx + len(sentence_chars), len(recognized_chars))
            
            if end_idx > len(recognized_chars):
                break
            
            # è®¡ç®—åŒ¹é…åˆ†æ•°
            match_count = sum(
                1 for i, char in enumerate(sentence_chars) 
                if start_idx + i < len(recognized_chars) and recognized_chars[start_idx + i] == char
            )
            
            if match_count > best_match_score:
                best_match_score = match_count
                best_start_idx = start_idx
                best_end_idx = min(start_idx + len(sentence_chars), len(recognized_chars))
        
        # è·å–æ—¶é—´æˆ³
        if best_start_idx < len(recognized_times) and best_end_idx > 0:
            start_time = recognized_times[best_start_idx]
            end_time = recognized_times[min(best_end_idx - 1, len(recognized_times) - 1)]
            
            # ç¡®ä¿æœ€å°æ—¶é•¿
            if end_time - start_time < 0.5:
                end_time = start_time + max(0.5, len(sentence_chars) * 0.15)
            
            aligned_segments.append({
                "start": start_time,
                "end": end_time,
                "text": sentence.strip()
            })
            
            # æ›´æ–°å½“å‰ä½ç½®
            current_char_idx = best_end_idx
        else:
            # æ— æ³•åŒ¹é…ï¼Œä½¿ç”¨ä¼°ç®—
            if aligned_segments:
                last_end = aligned_segments[-1]["end"]
                estimated_duration = max(1.0, len(sentence_chars) * 0.15)
                aligned_segments.append({
                    "start": last_end,
                    "end": last_end + estimated_duration,
                    "text": sentence.strip()
                })
    
    return aligned_segments


def fix_overlapping_timestamps(segments: List[Dict]) -> List[Dict]:
    """
    ä¿®å¤é‡å çš„æ—¶é—´æˆ³
    """
    if len(segments) == 0:
        return segments
    
    segments = sorted(segments, key=lambda x: x["start"])
    fixed_segments = []
    
    for i, segment in enumerate(segments):
        start = segment["start"]
        end = segment["end"]
        text = segment["text"]
        
        # è®¡ç®—åˆç†çš„æœ€å¤§æ—¶é•¿
        text_chars = len([c for c in text if c.strip() and c not in 'ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼šã€,.!?;: ã€€ã€Œã€ã€ã€""''ï¼ˆï¼‰()ã€ã€‘[]'])
        max_duration = max(2.0, 1.0 + text_chars * 0.4)
        min_duration = max(0.8, 0.5 + text_chars * 0.12)
        
        # ç¡®ä¿ä¸ä¸å‰ä¸€ä¸ªé‡å 
        if i > 0:
            prev_end = fixed_segments[-1]["end"]
            if start < prev_end:
                start = prev_end
        
        # ä¿®å¤æ—¶é•¿
        duration = end - start
        if duration > max_duration:
            end = start + max_duration
        if duration < min_duration:
            end = start + min_duration
        
        # æ·»åŠ é˜…è¯»ç¼“å†²
        end = end + 0.3
        
        # ç¡®ä¿ä¸è¶…è¿‡ä¸‹ä¸€ä¸ªå­—å¹•
        if i + 1 < len(segments):
            next_start = segments[i + 1]["start"]
            if end > next_start:
                end = max(start + 0.5, next_start - 0.05)
        
        # ç¡®ä¿æœ€å°æ—¶é•¿
        if end <= start:
            end = start + max(1.0, text_chars * 0.15)
        
        fixed_segments.append({
            "start": start,
            "end": end,
            "text": text
        })
    
    return fixed_segments


def generate_srt(segments: List[Dict], output_path: str):
    """
    ç”ŸæˆSRTå­—å¹•æ–‡ä»¶
    """
    with open(output_path, 'w', encoding='utf-8') as f:
        for i, segment in enumerate(segments, 1):
            f.write(f"{i}\n")
            start_time = format_timestamp(segment["start"])
            end_time = format_timestamp(segment["end"])
            f.write(f"{start_time} --> {end_time}\n")
            f.write(f"{segment['text']}\n")
            f.write("\n")
    
    print(f"SRTå­—å¹•æ–‡ä»¶å·²ç”Ÿæˆ: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="éŸ³é¢‘-æ–‡æœ¬å¯¹é½å·¥å…· (WhisperX ç‰ˆæœ¬)"
    )
    parser.add_argument(
        "audio",
        help="è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "text",
        help="è¾“å…¥æ–‡æœ¬æ–‡ä»¶è·¯å¾„æˆ–ç›´æ¥è¾“å…¥æ–‡æœ¬"
    )
    parser.add_argument(
        "-o", "--output",
        help="è¾“å‡ºSRTæ–‡ä»¶è·¯å¾„",
        default=None
    )
    parser.add_argument(
        "-m", "--model",
        help="Whisperæ¨¡å‹å¤§å°",
        default="base",
        choices=["tiny", "base", "small", "medium", "large"]
    )
    parser.add_argument(
        "-l", "--language",
        help="è¯­è¨€ä»£ç ",
        default="zh"
    )
    parser.add_argument(
        "-c", "--max-chars",
        help="æ¯è¡Œæœ€å¤§å­—ç¬¦æ•°",
        type=int,
        default=30
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
    if not os.path.exists(args.audio):
        print(f"é”™è¯¯: éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.audio}")
        sys.exit(1)
    
    # è¯»å–æ–‡æœ¬
    if os.path.exists(args.text):
        with open(args.text, 'r', encoding='utf-8') as f:
            text_content = f.read()
    else:
        text_content = args.text
    
    # è®¾ç½®è¾“å‡ºè·¯å¾„
    if args.output is None:
        base_name = os.path.splitext(args.audio)[0]
        output_path = f"{base_name}.srt"
    else:
        output_path = args.output
    
    # æ‰§è¡Œå¯¹é½
    print("\n" + "=" * 60)
    print("ğŸµ éŸ³é¢‘-æ–‡æœ¬å¯¹é½å·¥å…· (WhisperX ç‰ˆæœ¬)")
    print("=" * 60)
    
    segments = align_audio_text_whisperx(
        args.audio, 
        text_content, 
        args.model,
        max_chars=args.max_chars,
        language=args.language
    )
    
    # ç”ŸæˆSRT
    generate_srt(segments, output_path)
    
    print(f"\nâœ… å®Œæˆï¼å…±ç”Ÿæˆ {len(segments)} ä¸ªå­—å¹•æ®µè½")


if __name__ == "__main__":
    main()

