# 📝 文本对齐说明

## 🎯 程序的工作原理

### 之前的问题（已修复）❌

之前的版本**只做语音识别**，没有真正对齐用户提供的文本：
- ❌ 只使用 Whisper 识别音频
- ❌ 忽略用户提供的文本
- ❌ 结果有很多识别错误和错别字

### 现在的改进（新版本）✅

新版本实现了**真正的文本对齐**：

```
1. Whisper 识别音频 → 获取【时间戳】
                          ↓
2. 用户提供的文本    → 与时间戳对齐
                          ↓
3. 生成 SRT 字幕    → 使用【用户的准确文本】+ 【Whisper的时间戳】
```

**结果**：
- ✅ 字幕文本使用用户提供的准确内容（无错别字）
- ✅ 时间戳来自 Whisper 的精确识别
- ✅ 完美结合：准确的文本 + 精确的时间

---

## 🔧 对齐算法

### 方法1：词级对齐（默认，推荐）

使用 Whisper 的**词级时间戳**进行精确对齐：

1. **获取词级时间戳**
   ```
   Whisper识别: "欢迎" (0.0-0.5秒) "使用" (0.5-1.0秒) "本工具" (1.0-1.5秒)
   ```

2. **分割用户文本**
   ```
   用户文本: "欢迎使用本工具。这是第二句。"
   分割为: ["欢迎使用本工具", "这是第二句"]
   ```

3. **智能匹配**
   ```
   句子1 "欢迎使用本工具" → 匹配前3个词 → 时间: 0.0-1.5秒
   句子2 "这是第二句"     → 匹配接下来的词 → 时间: 1.5-3.0秒
   ```

### 方法2：段落级对齐（备用）

当没有词级时间戳时，使用段落级对齐：

1. **获取总时长**
   ```
   音频总长: 60秒
   用户文本句子数: 10句
   ```

2. **平均分配**
   ```
   每句平均: 60 ÷ 10 = 6秒
   句子1: 0-6秒
   句子2: 6-12秒
   ...
   ```

---

## 📊 对比示例

### 旧版本（只识别）❌

**输入**：
- 音频: "欢迎使用音频文本对齐工具"
- 用户文本: "欢迎使用音频-文本对齐工具"

**输出SRT**：
```srt
1
00:00:00,000 --> 00:00:03,000
欢迎使用音频文本对齐工具
```
注意：缺少中间的"-"，因为这是识别结果

### 新版本（真正对齐）✅

**输入**：
- 音频: "欢迎使用音频文本对齐工具"
- 用户文本: "欢迎使用音频-文本对齐工具"

**输出SRT**：
```srt
1
00:00:00,000 --> 00:00:03,000
欢迎使用音频-文本对齐工具
```
完美：使用用户提供的准确文本（包含"-"）

---

## 🎯 使用建议

### 1. 文本准备

**准确的文本**：
```
✅ 好: "欢迎使用音频-文本对齐工具。这个工具非常好用。"
❌ 差: "欢迎  使用   音频文本工具"  （空格不规范）
```

**分段清晰**：
```
✅ 好:
第一段内容。
第二段内容。
第三段内容。

❌ 差:
第一段内容第二段内容第三段内容  （没有断句）
```

### 2. 文本长度

**匹配音频内容**：
```
✅ 好: 文本长度与音频内容相符
❌ 差: 文本比音频长很多或短很多
```

### 3. 标点符号

**使用正确的标点**：
```
✅ 好: "你好。这是第一句。"  （中文句号）
✅ 好: "Hello. This is first."  （英文句点）
❌ 差: "你好这是第一句"  （没有标点）
```

---

## 🔍 验证对齐效果

### 检查点1：文本内容

打开生成的 SRT 文件，检查：
```srt
1
00:00:00,000 --> 00:00:03,000
[这里应该是你提供的原始文本，不是识别结果]
```

### 检查点2：时间准确度

播放音频，对照字幕：
- ✅ 时间戳准确：字幕出现时间与音频同步
- ✅ 无明显延迟：字幕不会提前或滞后太多
- ✅ 时长合理：每句字幕显示时间合适

### 检查点3：分段合理

```
✅ 好的分段:
1. 短句独立显示
2. 长句适当拆分
3. 每段2-3行，便于阅读

❌ 差的分段:
1. 所有内容挤在一起
2. 单个字幕太长
3. 分段过于频繁
```

---

## ⚙️ 高级选项

### 调整分段策略

编辑 `txt2srt.py` 中的 `split_text_into_segments` 函数：

```python
# 当前默认: 每段最多50个字符
segments = split_text_into_segments(text, max_chars=50)

# 调整为每段30个字符（更短的字幕）
segments = split_text_into_segments(text, max_chars=30)

# 调整为每段80个字符（更长的字幕）
segments = split_text_into_segments(text, max_chars=80)
```

### 自定义对齐算法

如果默认对齐效果不理想，可以修改 `align_user_text_with_timestamps` 函数：

```python
# 在 txt2srt.py 中找到这个函数
def align_user_text_with_timestamps(user_sentences, words_with_time):
    # 在这里实现你自己的对齐逻辑
    pass
```

---

## 📖 工作流程示例

### 完整流程

**1. 准备文件**
```
音频: podcast.mp3 (10分钟)
文本: script.txt (完整文稿，标点清晰)
```

**2. 启动程序**
```bash
start_ui.bat
```

**3. 上传文件**
```
- 上传 podcast.mp3
- 上传 script.txt
- 选择模型: Base
```

**4. 处理过程**
```
🎯 步骤1: 使用Whisper识别音频获取时间戳...
   ↓
🎯 步骤2: 对齐用户提供的文本...
   ↓
✅ 对齐完成！生成了 45 个字幕段落
```

**5. 下载结果**
```
podcast.srt (包含准确文本 + 精确时间戳)
```

**6. 验证效果**
```
用播放器打开音频和字幕：
- 检查文本是否是你提供的原文
- 检查时间是否准确同步
```

---

## 🐛 常见问题

### Q1: 字幕文本还是有错别字？

**A**: 请确认：
1. 使用的是最新版本的代码
2. 在日志中看到 "步骤2: 对齐用户提供的文本..."
3. 如果还有问题，可能是文本没有正确上传

### Q2: 时间戳不准确？

**A**: 可能原因：
1. 音频质量差（噪音太多）
2. 模型太小（建议用 small 或 medium）
3. 文本与音频内容差异太大

### Q3: 有些句子时间重叠？

**A**: 这是对齐算法需要优化，可以：
1. 调整文本分段（更短或更长）
2. 使用更大的模型获得更准确的时间戳
3. 手动调整 SRT 文件

### Q4: 处理很慢？

**A**: 参考 [GPU_SETUP.md](GPU_SETUP.md) 配置GPU加速

---

## 📊 性能指标

| 音频长度 | 模型 | 处理时间(CPU) | 处理时间(GPU) | 准确度 |
|---------|------|--------------|--------------|--------|
| 5分钟 | base | 3-5分钟 | 20-30秒 | 良好 |
| 5分钟 | small | 5-10分钟 | 30-60秒 | 很好 |
| 5分钟 | medium | 15-30分钟 | 1-2分钟 | 优秀 |

---

## 💡 最佳实践

1. **文本质量最重要**
   - 确保文本准确无误
   - 标点符号规范
   - 分段清晰合理

2. **选择合适的模型**
   - 测试: tiny, base
   - 日常: base, small
   - 专业: medium, large

3. **验证输出**
   - 总是检查生成的字幕
   - 对照音频播放验证
   - 必要时手动微调

4. **优化性能**
   - 使用GPU加速
   - 分段处理长音频
   - 选择合适的模型大小

---

**更新日期**: 2025年11月  
**版本**: 2.0（支持真正的文本对齐）

