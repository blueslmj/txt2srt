#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
éŸ³é¢‘-æ–‡æœ¬å¯¹é½å·¥å…·ï¼Œç”ŸæˆSRTå­—å¹•æ–‡ä»¶
"""

import os
import sys
import argparse
import whisper
import stable_whisper
from typing import List, Dict, Tuple
import re
from dtw import dtw
import numpy as np


def format_timestamp(seconds: float) -> str:
    """
    å°†ç§’æ•°è½¬æ¢ä¸ºSRTæ—¶é—´æˆ³æ ¼å¼ (HH:MM:SS,mmm)
    """
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    milliseconds = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"


def split_text_into_segments(text: str, max_chars: int = 50) -> List[str]:
    """
    å°†é•¿æ–‡æœ¬åˆ†å‰²æˆé€‚åˆå­—å¹•æ˜¾ç¤ºçš„çŸ­å¥
    
    ä¼˜å…ˆçº§ï¼š
    1. æ¢è¡Œç¬¦ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œå¼ºåˆ¶åˆ†å¥ï¼‰
    2. å¥å­æ ‡ç‚¹ï¼ˆã€‚ï¼ï¼Ÿï¼›ç­‰ï¼‰
    3. é•¿åº¦é™åˆ¶ï¼ˆå¦‚æœå¥å­å¤ªé•¿ï¼Œå¼ºåˆ¶åˆ†å‰²ï¼‰
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        max_chars: æ¯æ®µæœ€å¤§å­—ç¬¦æ•°
    
    Returns:
        åˆ†å‰²åçš„æ–‡æœ¬æ®µè½åˆ—è¡¨
    """
    segments = []
    
    # ç¬¬ä¸€æ­¥ï¼šæŒ‰æ¢è¡Œç¬¦åˆ†å‰²ï¼ˆä¿ç•™åŸæ–‡çš„æ®µè½ç»“æ„ï¼‰
    lines = text.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # ç¬¬äºŒæ­¥ï¼šæŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²æ¯ä¸€è¡Œ
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿï¼›\.,!?;])', line)
        
        current_segment = ""
        
        for i in range(0, len(sentences), 2):
            sentence = sentences[i]
            punct = sentences[i + 1] if i + 1 < len(sentences) else ""
            
            if not sentence.strip():
                continue
                
            potential_segment = current_segment + sentence + punct
            
            # å¦‚æœç´¯ç§¯çš„å¥å­æ²¡è¶…è¿‡é•¿åº¦é™åˆ¶ï¼Œç»§ç»­ç´¯ç§¯
            if len(potential_segment) <= max_chars:
                current_segment = potential_segment
            else:
                # è¶…è¿‡é™åˆ¶äº†ï¼Œè¾“å‡ºå½“å‰æ®µè½
                if current_segment:
                    segments.append(current_segment.strip())
                current_segment = sentence + punct
        
        # æ¯ä¸€è¡Œç»“æŸåï¼Œå¼ºåˆ¶è¾“å‡ºç´¯ç§¯çš„å†…å®¹ï¼ˆé‡è¦ï¼ï¼‰
        if current_segment.strip():
            segments.append(current_segment.strip())
    
    return segments


def align_audio_text(audio_path: str, text: str, model_name: str = "base", use_gpu: bool = True) -> List[Dict]:
    """
    å…ˆç”¨Whisperè¯†åˆ«è·å–å‡†ç¡®çš„æ—¶é—´æˆ³ï¼Œç„¶åç”¨ç”¨æˆ·æ–‡æœ¬æ›¿æ¢è¯†åˆ«æ–‡æœ¬
    
    æ ¸å¿ƒæ€è·¯ï¼š
    1. Whisperè¯†åˆ«éŸ³é¢‘ â†’ è·å–å‡†ç¡®çš„æ—¶é—´æˆ³ï¼ˆåŸºäºéŸ³é¢‘ç‰¹å¾ï¼‰
    2. æå–è¯†åˆ«å‡ºçš„å¥å­ + æ—¶é—´æˆ³
    3. ä½¿ç”¨DTWç®—æ³•åŒ¹é…è¯†åˆ«å¥å­å’Œç”¨æˆ·å¥å­
    4. ç”¨ç”¨æˆ·çš„æ­£ç¡®æ–‡æœ¬æ›¿æ¢è¯†åˆ«æ–‡æœ¬ï¼Œä½†ä¿ç•™Whisperçš„å‡†ç¡®æ—¶é—´æˆ³
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        text: ç”¨æˆ·æä¾›çš„å‡†ç¡®æ–‡æœ¬
        model_name: Whisperæ¨¡å‹å¤§å° (tiny, base, small, medium, large)
        use_gpu: æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ
    
    Returns:
        åŒ…å«æ—¶é—´æˆ³çš„æ–‡æœ¬æ®µè½åˆ—è¡¨ï¼ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„æ–‡æœ¬ + Whisperçš„æ—¶é—´æˆ³ï¼‰
    """
    import torch
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    device = "cuda" if use_gpu and torch.cuda.is_available() else "cpu"
    if use_gpu and not torch.cuda.is_available():
        print("âš ï¸ è­¦å‘Š: GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUå¤„ç†ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
        print("   å¦‚éœ€GPUåŠ é€Ÿï¼Œè¯·å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch")
    else:
        print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device.upper()}")
    
    print(f"åŠ è½½Whisperæ¨¡å‹ (stable-tså¢å¼ºç‰ˆ): {model_name}...")
    # ä½¿ç”¨stable-tsåŠ è½½æ¨¡å‹ï¼ˆæä¾›æ›´ç²¾ç¡®çš„æ—¶é—´æˆ³ï¼‰
    model = stable_whisper.load_model(model_name, device=device)
    
    print(f"æ­£åœ¨å¤„ç†éŸ³é¢‘æ–‡ä»¶: {audio_path}")
    print("ğŸ¯ æ­¥éª¤1: ä½¿ç”¨Whisperè¯†åˆ«éŸ³é¢‘ï¼Œè·å–å‡†ç¡®çš„æ—¶é—´æˆ³...")
    
    # ä½¿ç”¨stable-tsè¯†åˆ«éŸ³é¢‘ï¼ˆè·å–ç²¾ç¡®çš„å¥å­çº§æ—¶é—´æˆ³ï¼‰
    result = model.transcribe(
        audio_path,
        language="zh",
        word_timestamps=True,
        verbose=False,
        regroup=True,  # é‡æ–°åˆ†ç»„ï¼Œè·å¾—åˆç†çš„å¥å­åˆ‡åˆ†
    )
    
    # æå–è¯†åˆ«å‡ºçš„å¥å­å’Œæ—¶é—´æˆ³
    recognized_segments = []
    for segment in result.segments:
        recognized_segments.append({
            "start": segment.start,
            "end": segment.end,
            "text": segment.text.strip()
        })
    
    print(f"   Whisperè¯†åˆ«åˆ° {len(recognized_segments)} ä¸ªè¯­éŸ³æ®µè½")
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªè¯†åˆ«ç»“æœï¼ˆè°ƒè¯•ç”¨ï¼‰
    if len(recognized_segments) > 0:
        print("\nğŸ“ è¯†åˆ«çš„å‰3ä¸ªæ®µè½ï¼ˆå«æ—¶é—´æˆ³ï¼‰:")
        for i, seg in enumerate(recognized_segments[:3]):
            print(f"   [{i+1}] {seg['start']:.1f}s - {seg['end']:.1f}s: {seg['text'][:30]}...")
    
    print("\nğŸ¯ æ­¥éª¤2: å°†ç”¨æˆ·æ–‡æœ¬åˆ†å‰²æˆå¥å­...")
    user_sentences = split_text_into_segments(text)
    print(f"   ç”¨æˆ·æ–‡æœ¬æœ‰ {len(user_sentences)} ä¸ªå¥å­")
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªç”¨æˆ·å¥å­
    if len(user_sentences) > 0:
        print("\nğŸ“ ç”¨æˆ·çš„å‰3ä¸ªå¥å­:")
        for i, sentence in enumerate(user_sentences[:3]):
            print(f"   [{i+1}] {sentence[:30]}...")
    
    print("\nğŸ¯ æ­¥éª¤3: ä½¿ç”¨DTWç®—æ³•åŒ¹é…è¯†åˆ«æ–‡æœ¬å’Œç”¨æˆ·æ–‡æœ¬...")
    
    # ä½¿ç”¨DTWåœ¨å­—ç¬¦çº§åˆ«åŒ¹é…
    aligned_segments = match_user_text_to_timestamps(
        recognized_segments, 
        user_sentences
    )
    
    print(f"\nğŸ¯ æ­¥éª¤4: ä¿®å¤æ—¶é—´æˆ³é‡å é—®é¢˜...")
    
    # ä¿®å¤é‡å çš„æ—¶é—´æˆ³ï¼Œç¡®ä¿ä¸¥æ ¼æŒ‰æ—¶é—´é¡ºåº
    aligned_segments = fix_overlapping_timestamps(aligned_segments)
    
    print(f"\nâœ… å¯¹é½å®Œæˆï¼ç”Ÿæˆäº† {len(aligned_segments)} ä¸ªå­—å¹•æ®µè½")
    print(f"   ä¿ç•™äº†Whisperçš„å‡†ç¡®æ—¶é—´æˆ³ï¼Œä½¿ç”¨äº†ç”¨æˆ·çš„æ­£ç¡®æ–‡æœ¬")
    
    return aligned_segments


def match_user_text_to_timestamps(recognized_segments: List[Dict], user_sentences: List[str]) -> List[Dict]:
    """
    ä½¿ç”¨DTWç®—æ³•åŒ¹é…ç”¨æˆ·å¥å­å’Œè¯†åˆ«å¥å­ï¼Œç”¨ç”¨æˆ·æ–‡æœ¬æ›¿æ¢è¯†åˆ«æ–‡æœ¬ä½†ä¿ç•™æ—¶é—´æˆ³
    
    ç­–ç•¥ï¼š
    1. æå–è¯†åˆ«å¥å­å’Œç”¨æˆ·å¥å­çš„å­—ç¬¦åºåˆ—
    2. ä½¿ç”¨DTWæ‰¾åˆ°å­—ç¬¦çº§åˆ«çš„å¯¹åº”å…³ç³»
    3. æ ¹æ®å¯¹åº”å…³ç³»ï¼Œå°†ç”¨æˆ·å¥å­æ˜ å°„åˆ°è¯†åˆ«å¥å­çš„æ—¶é—´æˆ³
    
    Args:
        recognized_segments: Whisperè¯†åˆ«çš„å¥å­åˆ—è¡¨ï¼ˆå«å‡†ç¡®æ—¶é—´æˆ³ï¼‰
        user_sentences: ç”¨æˆ·æä¾›çš„æ­£ç¡®å¥å­åˆ—è¡¨
    
    Returns:
        å¯¹é½åçš„å¥å­åˆ—è¡¨ï¼ˆç”¨æˆ·æ–‡æœ¬ + Whisperæ—¶é—´æˆ³ï¼‰
    """
    if len(recognized_segments) == 0 or len(user_sentences) == 0:
        print("âš ï¸ æ–‡æœ¬ä¸ºç©ºï¼Œæ— æ³•å¯¹é½")
        return []
    
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·çš„è¾…åŠ©å‡½æ•°
    def remove_punctuation(text):
        return ''.join([c for c in text if c.strip() and c not in 'ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼šã€,.!?;: ã€€ã€Œã€ã€ã€""''ï¼ˆï¼‰()ã€ã€‘[]'])
    
    # æå–è¯†åˆ«æ–‡æœ¬çš„å­—ç¬¦åºåˆ—ï¼ˆå»é™¤æ ‡ç‚¹ï¼‰
    recognized_text = ''.join([seg["text"] for seg in recognized_segments])
    recognized_chars = list(remove_punctuation(recognized_text))
    
    # æå–ç”¨æˆ·æ–‡æœ¬çš„å­—ç¬¦åºåˆ—ï¼ˆå»é™¤æ ‡ç‚¹ï¼‰
    user_text = ''.join(user_sentences)
    user_chars = list(remove_punctuation(user_text))
    
    print(f"   è¯†åˆ«æ–‡æœ¬: {len(recognized_chars)} ä¸ªå­—ç¬¦")
    print(f"   ç”¨æˆ·æ–‡æœ¬: {len(user_chars)} ä¸ªå­—ç¬¦")
    
    # æ„å»ºDTWè·ç¦»çŸ©é˜µ
    n_user = len(user_chars)
    n_recognized = len(recognized_chars)
    
    distance_matrix = np.zeros((n_user, n_recognized))
    for i in range(n_user):
        for j in range(n_recognized):
            distance_matrix[i, j] = 0 if user_chars[i] == recognized_chars[j] else 1
    
    # è¿è¡ŒDTWç®—æ³•
    print("   è¿è¡ŒDTWç®—æ³•è¿›è¡Œå­—ç¬¦çº§åŒ¹é…...")
    alignment = dtw(distance_matrix)
    
    # è·å–å¯¹é½è·¯å¾„
    path = list(zip(alignment.index1, alignment.index2))
    
    match_rate = (1 - alignment.normalizedDistance) * 100
    print(f"   âœ… DTWåŒ¹é…æˆåŠŸï¼Œç›¸ä¼¼åº¦: {match_rate:.1f}%")
    
    # ä¸ºæ¯ä¸ªè¯†åˆ«å­—ç¬¦å»ºç«‹ç´¢å¼•ï¼ˆå­—ç¬¦ â†’ æ‰€å±çš„segmentå’Œsegmentå†…çš„ä½ç½®ï¼‰
    recognized_char_to_segment = []
    for seg_idx, segment in enumerate(recognized_segments):
        seg_text = remove_punctuation(segment["text"])
        for char_idx, char in enumerate(seg_text):
            recognized_char_to_segment.append({
                "seg_idx": seg_idx,
                "char_idx": char_idx,
                "total_chars": len(seg_text),
                "segment": segment
            })
    
    # ä¸ºæ¯ä¸ªç”¨æˆ·å­—ç¬¦æ‰¾åˆ°å¯¹åº”çš„è¯†åˆ«segment
    user_char_to_segment = [None] * n_user
    for user_idx, rec_idx in path:
        if rec_idx < len(recognized_char_to_segment):
            user_char_to_segment[user_idx] = recognized_char_to_segment[rec_idx]
    
    # å»ºç«‹æ›´ç²¾ç»†çš„æ˜ å°„ï¼šä¸ºæ¯ä¸ªç”¨æˆ·å­—ç¬¦æ‰¾åˆ°å¯¹åº”çš„æ—¶é—´æˆ³
    user_char_times = []
    for i in range(n_user):
        if user_char_to_segment[i] is not None:
            seg_info = user_char_to_segment[i]
            segment = seg_info["segment"]
            
            # åœ¨segmentå†…éƒ¨è¿›è¡Œæ—¶é—´æ’å€¼
            segment_duration = segment["end"] - segment["start"]
            total_chars = seg_info["total_chars"]
            
            if total_chars > 0:
                char_time = segment["start"] + (seg_info["char_idx"] / total_chars) * segment_duration
            else:
                char_time = segment["start"]
            
            user_char_times.append(char_time)
        else:
            # æ²¡æœ‰åŒ¹é…åˆ°ï¼Œç¨åæ’å€¼
            user_char_times.append(None)
    
    # å¯¹æœªåŒ¹é…çš„å­—ç¬¦è¿›è¡Œçº¿æ€§æ’å€¼
    for i in range(n_user):
        if user_char_times[i] is None:
            # å‘å‰æ‰¾æœ€è¿‘çš„æœ‰æ•ˆæ—¶é—´
            prev_time = 0.0
            for j in range(i - 1, -1, -1):
                if user_char_times[j] is not None:
                    prev_time = user_char_times[j]
                    break
            
            # å‘åæ‰¾æœ€è¿‘çš„æœ‰æ•ˆæ—¶é—´
            next_time = recognized_segments[-1]["end"] if recognized_segments else 0.0
            for j in range(i + 1, n_user):
                if user_char_times[j] is not None:
                    next_time = user_char_times[j]
                    break
            
            user_char_times[i] = (prev_time + next_time) / 2
    
    # ç°åœ¨ä¸ºæ¯ä¸ªç”¨æˆ·å¥å­åˆ†é…æ—¶é—´æˆ³
    aligned_segments = []
    char_idx = 0
    
    for sentence in user_sentences:
        if not sentence.strip():
            continue
        
        # æå–å¥å­çš„çº¯å­—ç¬¦
        sentence_chars = remove_punctuation(sentence)
        
        if len(sentence_chars) == 0:
            # çº¯æ ‡ç‚¹å¥å­ï¼Œä½¿ç”¨ä¼°ç®—æ—¶é•¿
            if aligned_segments:
                last_end = aligned_segments[-1]["end"]
                aligned_segments.append({
                    "start": last_end,
                    "end": last_end + 0.5,
                    "text": sentence.strip()
                })
            continue
        
        # æ‰¾åˆ°è¿™ä¸ªå¥å­å¯¹åº”çš„å­—ç¬¦èŒƒå›´
        start_char_idx = char_idx
        end_char_idx = min(char_idx + len(sentence_chars), n_user)
        
        if start_char_idx >= n_user:
            # è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨ä¼°ç®—
            if aligned_segments:
                last_end = aligned_segments[-1]["end"]
                estimated_duration = len(sentence_chars) * 0.15
                aligned_segments.append({
                    "start": last_end,
                    "end": last_end + estimated_duration,
                    "text": sentence.strip()
                })
                print(f"   âš ï¸ [{len(aligned_segments)}] è¶…å‡ºåŒ¹é…èŒƒå›´ï¼Œä½¿ç”¨ä¼°ç®—æ—¶é•¿")
            break
        
        # ä½¿ç”¨å­—ç¬¦æ—¶é—´æˆ³
        start_time = user_char_times[start_char_idx]
        end_time = user_char_times[min(end_char_idx - 1, n_user - 1)]
        
        # ç¡®ä¿æ—¶é•¿åˆç†ï¼ˆè‡³å°‘0.5ç§’ï¼‰
        if end_time - start_time < 0.5:
            end_time = start_time + max(0.5, len(sentence_chars) * 0.15)
        
        aligned_segments.append({
            "start": start_time,
            "end": end_time,
            "text": sentence.strip()
        })
        
        # è°ƒè¯•ä¿¡æ¯ï¼ˆå‰5å¥å’Œå5å¥ï¼‰
        if len(aligned_segments) <= 5 or len(user_sentences) - len(aligned_segments) < 5:
            duration = end_time - start_time
            print(f"   [{len(aligned_segments)}] {start_time:.1f}s-{end_time:.1f}s ({duration:.1f}s): {sentence[:20]}...")
        
        char_idx = end_char_idx
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å¥å­éƒ½è¢«å¤„ç†äº†
    if len(aligned_segments) < len(user_sentences):
        missing = len(user_sentences) - len(aligned_segments)
        print(f"   âš ï¸ è­¦å‘Š: {missing} ä¸ªå¥å­æœªèƒ½åŒ¹é…ï¼Œå°†ä½¿ç”¨ä¼°ç®—æ—¶é•¿")
    
    return aligned_segments


def calculate_similarity(text1: str, text2: str) -> float:
    """
    è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦ï¼ˆåŸºäºæœ€é•¿å…¬å…±å­åºåˆ—ï¼‰
    
    Args:
        text1: ç¬¬ä¸€ä¸ªæ–‡æœ¬
        text2: ç¬¬äºŒä¸ªæ–‡æœ¬
    
    Returns:
        ç›¸ä¼¼åº¦ (0-1ä¹‹é—´)
    """
    # ç§»é™¤æ ‡ç‚¹å’Œç©ºæ ¼
    clean1 = ''.join([c for c in text1 if c.strip() and c not in 'ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼šã€,.!?;: ã€€ã€Œã€ã€ã€""''ï¼ˆï¼‰()ã€ã€‘[]'])
    clean2 = ''.join([c for c in text2 if c.strip() and c not in 'ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼šã€,.!?;: ã€€ã€Œã€ã€ã€""''ï¼ˆï¼‰()ã€ã€‘[]'])
    
    if len(clean1) == 0 or len(clean2) == 0:
        return 0.0
    
    # è®¡ç®—æœ€é•¿å…¬å…±å­åºåˆ—é•¿åº¦ï¼ˆç®€åŒ–ç‰ˆï¼Œç”¨äºå¿«é€ŸåŒ¹é…ï¼‰
    # è¿™é‡Œç”¨ç®€å•çš„å­—ç¬¦åŒ¹é…è®¡æ•°
    matches = 0
    for char in clean1:
        if char in clean2:
            matches += 1
    
    # ç›¸ä¼¼åº¦ = åŒ¹é…å­—ç¬¦æ•° / è¾ƒé•¿æ–‡æœ¬çš„é•¿åº¦
    similarity = matches / max(len(clean1), len(clean2))
    
    return similarity


def align_user_text_with_timestamps(user_sentences: List[str], words_with_time: List[Dict]) -> List[Dict]:
    """
    å°†ç”¨æˆ·æä¾›çš„æ–‡æœ¬ä¸å¸¦æ—¶é—´æˆ³çš„è¯†åˆ«è¯å¯¹é½ï¼ˆåŸºäºæ»‘åŠ¨çª—å£åŒ¹é…ï¼‰
    
    Args:
        user_sentences: ç”¨æˆ·æ–‡æœ¬åˆ†å‰²åçš„å¥å­åˆ—è¡¨
        words_with_time: Whisperè¯†åˆ«å‡ºçš„è¯åŠæ—¶é—´æˆ³
    
    Returns:
        å¯¹é½åçš„æ®µè½åˆ—è¡¨
    """
    aligned_segments = []
    total_words = len(words_with_time)
    
    if total_words == 0:
        print("âš ï¸ è­¦å‘Šï¼šWhisperæ²¡æœ‰è¯†åˆ«å‡ºä»»ä½•è¯ï¼Œæ— æ³•å¯¹é½")
        return aligned_segments
    
    audio_duration = words_with_time[-1]["end"]
    
    print(f"ğŸ“Š å¯¹é½ç»Ÿè®¡ï¼š")
    print(f"   - ç”¨æˆ·æ–‡æœ¬: {len(user_sentences)} ä¸ªå¥å­")
    print(f"   - Whisperè¯†åˆ«: {total_words} ä¸ªè¯")
    print(f"   - éŸ³é¢‘æ—¶é•¿: {audio_duration:.1f} ç§’")
    print(f"ğŸ” å¼€å§‹æ»‘åŠ¨çª—å£åŒ¹é…...")
    
    # å½“å‰åœ¨è¯åˆ—è¡¨ä¸­çš„èµ·å§‹ä½ç½®
    current_word_idx = 0
    
    for sent_idx, user_sentence in enumerate(user_sentences):
        if not user_sentence.strip():
            continue
        
        # ç§»é™¤æ ‡ç‚¹çš„ç”¨æˆ·å¥å­
        user_clean = ''.join([c for c in user_sentence if c.strip() and c not in 'ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼šã€,.!?;: ã€€ã€Œã€ã€ã€""''ï¼ˆï¼‰()ã€ã€‘[]'])
        
        if len(user_clean) == 0:
            continue
        
        user_len = len(user_clean)
        
        # ä¼°ç®—è¿™ä¸ªå¥å­éœ€è¦å¤šå°‘ä¸ªè¯ï¼ˆä¸­æ–‡å¹³å‡ä¸€ä¸ªè¯2-3ä¸ªå­—ï¼‰
        estimated_words = max(5, int(user_len / 2.5))
        
        best_match_score = 0
        best_start_idx = current_word_idx
        best_end_idx = min(current_word_idx + estimated_words, total_words)
        
        # æ»‘åŠ¨çª—å£æŸ¥æ‰¾æœ€ä½³åŒ¹é…
        # çª—å£å¤§å°èŒƒå›´ï¼šestimated_wordsçš„50% åˆ° 200%
        min_window = max(3, int(estimated_words * 0.5))
        max_window = min(int(estimated_words * 2), total_words - current_word_idx)
        
        for window_size in range(min_window, max_window + 1):
            # å°è¯•ä¸åŒçš„èµ·å§‹ä½ç½®ï¼ˆå…è®¸å‘å‰æˆ–å‘åå¾®è°ƒï¼‰
            for start_offset in range(-3, 4):
                start_idx = current_word_idx + start_offset
                end_idx = start_idx + window_size
                
                if start_idx < 0 or end_idx > total_words:
                    continue
                
                # æå–è¿™ä¸ªçª—å£å†…çš„æ–‡æœ¬
                window_text = ""
                for i in range(start_idx, end_idx):
                    word = words_with_time[i]["word"].strip()
                    clean_word = ''.join([c for c in word if c not in 'ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼šã€,.!?;: ã€€ã€Œã€ã€ã€""''ï¼ˆï¼‰()ã€ã€‘[]'])
                    window_text += clean_word
                
                # è®¡ç®—ç›¸ä¼¼åº¦
                similarity = calculate_similarity(user_sentence, window_text)
                
                # å¦‚æœç›¸ä¼¼åº¦æ›´é«˜ï¼Œæ›´æ–°æœ€ä½³åŒ¹é…
                if similarity > best_match_score:
                    best_match_score = similarity
                    best_start_idx = start_idx
                    best_end_idx = end_idx
        
        # ä½¿ç”¨æœ€ä½³åŒ¹é…çš„æ—¶é—´æˆ³
        if best_start_idx < total_words and best_end_idx > best_start_idx:
            start_time = words_with_time[best_start_idx]["start"]
            end_time = words_with_time[min(best_end_idx - 1, total_words - 1)]["end"]
            
            aligned_segments.append({
                "start": start_time,
                "end": end_time,
                "text": user_sentence.strip()
            })
            
            # æ›´æ–°å½“å‰ä½ç½®
            current_word_idx = best_end_idx
            
            # è°ƒè¯•ä¿¡æ¯ï¼ˆå‰10å¥ï¼‰
            if len(aligned_segments) <= 10:
                duration = end_time - start_time
                print(f"   å¥å­ {len(aligned_segments)}: {start_time:.1f}s - {end_time:.1f}s ({duration:.1f}s), ç›¸ä¼¼åº¦ {best_match_score*100:.0f}%")
        else:
            # å¦‚æœæ— æ³•åŒ¹é…ï¼Œä½¿ç”¨ä¼°ç®—çš„æ—¶é—´
            if aligned_segments:
                last_end = aligned_segments[-1]["end"]
                estimated_duration = len(user_clean) * 0.3  # å‡è®¾æ¯å­—0.3ç§’
                aligned_segments.append({
                    "start": last_end,
                    "end": min(last_end + estimated_duration, audio_duration),
                    "text": user_sentence.strip()
                })
            else:
                # ç¬¬ä¸€å¥è¯æ‰¾ä¸åˆ°åŒ¹é…ï¼Œä»0å¼€å§‹
                estimated_duration = len(user_clean) * 0.3
                aligned_segments.append({
                    "start": 0.0,
                    "end": min(estimated_duration, audio_duration),
                    "text": user_sentence.strip()
                })
    
    print(f"âœ… å¯¹é½å®Œæˆï¼ç”Ÿæˆäº† {len(aligned_segments)} ä¸ªå­—å¹•æ®µè½")
    
    return aligned_segments


def align_text_by_segments(whisper_segments: List[Dict], user_sentences: List[str]) -> List[Dict]:
    """
    å½“æ²¡æœ‰è¯çº§æ—¶é—´æˆ³æ—¶ï¼Œä½¿ç”¨æ®µè½çº§å¯¹é½
    
    Args:
        whisper_segments: Whisperè¯†åˆ«çš„æ®µè½
        user_sentences: ç”¨æˆ·æ–‡æœ¬å¥å­
    
    Returns:
        å¯¹é½åçš„æ®µè½åˆ—è¡¨
    """
    aligned_segments = []
    
    # ç®€å•ç­–ç•¥ï¼šå¹³å‡åˆ†é…æ—¶é—´
    if not whisper_segments:
        return aligned_segments
    
    total_duration = whisper_segments[-1]["end"]
    sentence_duration = total_duration / len(user_sentences)
    
    for i, sentence in enumerate(user_sentences):
        if sentence.strip():
            aligned_segments.append({
                "start": i * sentence_duration,
                "end": (i + 1) * sentence_duration,
                "text": sentence.strip()
            })
    
    return aligned_segments


def generate_srt(segments: List[Dict], output_path: str):
    """
    ç”ŸæˆSRTå­—å¹•æ–‡ä»¶
    
    Args:
        segments: åŒ…å«æ—¶é—´æˆ³çš„æ–‡æœ¬æ®µè½åˆ—è¡¨
        output_path: è¾“å‡ºSRTæ–‡ä»¶è·¯å¾„
    """
    with open(output_path, 'w', encoding='utf-8') as f:
        for i, segment in enumerate(segments, 1):
            # å†™å…¥åºå·
            f.write(f"{i}\n")
            # å†™å…¥æ—¶é—´æˆ³
            start_time = format_timestamp(segment["start"])
            end_time = format_timestamp(segment["end"])
            f.write(f"{start_time} --> {end_time}\n")
            # å†™å…¥æ–‡æœ¬
            f.write(f"{segment['text']}\n")
            # ç©ºè¡Œåˆ†éš”
            f.write("\n")
    
    print(f"SRTå­—å¹•æ–‡ä»¶å·²ç”Ÿæˆ: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="éŸ³é¢‘-æ–‡æœ¬å¯¹é½å·¥å…·ï¼Œç”ŸæˆSRTå­—å¹•æ–‡ä»¶"
    )
    parser.add_argument(
        "audio",
        help="è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (æ”¯æŒ mp3, wav, m4a, flac, ogg ç­‰æ ¼å¼)"
    )
    parser.add_argument(
        "text",
        help="è¾“å…¥æ–‡æœ¬æ–‡ä»¶è·¯å¾„ æˆ– ç›´æ¥è¾“å…¥æ–‡æœ¬å†…å®¹"
    )
    parser.add_argument(
        "-o", "--output",
        help="è¾“å‡ºSRTæ–‡ä»¶è·¯å¾„ (é»˜è®¤: audio_name.srt)",
        default=None
    )
    parser.add_argument(
        "-m", "--model",
        help="Whisperæ¨¡å‹å¤§å° (tiny, base, small, medium, large)",
        default="base",
        choices=["tiny", "base", "small", "medium", "large"]
    )
    parser.add_argument(
        "-l", "--language",
        help="è¯­è¨€ä»£ç  (zh: ä¸­æ–‡, en: è‹±æ–‡, None: è‡ªåŠ¨æ£€æµ‹)",
        default="zh"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.audio):
        print(f"é”™è¯¯: éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.audio}")
        sys.exit(1)
    
    # è¯»å–æ–‡æœ¬
    if os.path.exists(args.text):
        with open(args.text, 'r', encoding='utf-8') as f:
            text_content = f.read()
        print(f"ä»æ–‡ä»¶è¯»å–æ–‡æœ¬: {args.text}")
    else:
        text_content = args.text
        print("ä½¿ç”¨ç›´æ¥æä¾›çš„æ–‡æœ¬å†…å®¹")
    
    # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„
    if args.output is None:
        base_name = os.path.splitext(args.audio)[0]
        output_path = f"{base_name}.srt"
    else:
        output_path = args.output
    
    # æ‰§è¡Œå¯¹é½
    print("\nå¼€å§‹éŸ³é¢‘-æ–‡æœ¬å¯¹é½...")
    segments = align_audio_text(args.audio, text_content, args.model)
    
    # ç”ŸæˆSRTæ–‡ä»¶
    generate_srt(segments, output_path)
    
    print(f"\nâœ… å®Œæˆï¼å…±ç”Ÿæˆ {len(segments)} ä¸ªå­—å¹•æ®µè½")


if __name__ == "__main__":
    main()



def fix_overlapping_timestamps(segments: List[Dict]) -> List[Dict]:
    """
    ä¿®å¤é‡å çš„æ—¶é—´æˆ³ï¼Œç¡®ä¿å­—å¹•æ®µè½ä¸¥æ ¼æŒ‰æ—¶é—´é¡ºåºæ’åˆ—ä¸”ä¸é‡å 
    
    Args:
        segments: åˆå§‹å¯¹é½çš„æ®µè½åˆ—è¡¨ï¼ˆå¯èƒ½æœ‰é‡å ï¼‰
    
    Returns:
        ä¿®å¤åçš„æ®µè½åˆ—è¡¨ï¼ˆæ— é‡å ï¼‰
    """
    if len(segments) == 0:
        return segments
    
    # æŒ‰å¼€å§‹æ—¶é—´æ’åº
    segments = sorted(segments, key=lambda x: x["start"])
    
    fixed_segments = []
    
    for i, segment in enumerate(segments):
        start = segment["start"]
        end = segment["end"]
        text = segment["text"]
        
        # å¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªæ®µè½ï¼Œç¡®ä¿å¼€å§‹æ—¶é—´ä¸æ—©äºä¸Šä¸€ä¸ªæ®µè½çš„ç»“æŸæ—¶é—´
        if i > 0:
            prev_end = fixed_segments[-1]["end"]
            if start < prev_end:
                # é‡å äº†ï¼Œè°ƒæ•´å¼€å§‹æ—¶é—´ä¸ºä¸Šä¸€ä¸ªæ®µè½ç»“æŸæ—¶é—´
                start = prev_end
                # å¦‚æœè°ƒæ•´åç»“æŸæ—¶é—´ä¹Ÿå˜å¾—ä¸åˆç†ï¼Œé‡æ–°è®¡ç®—
                if end <= start:
                    # æ ¹æ®æ–‡æœ¬é•¿åº¦ä¼°ç®—åˆç†çš„æ—¶é•¿ï¼ˆæ¯ä¸ªå­—çº¦0.15ç§’ï¼‰
                    text_chars = len([c for c in text if c.strip() and c not in 'ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼šã€,.!?;: ã€€ã€Œã€ã€ã€""''ï¼ˆï¼‰()ã€ã€‘[]'])
                    estimated_duration = max(1.0, text_chars * 0.15)
                    end = start + estimated_duration
        
        # ç»™ç»“æŸæ—¶é—´æ·»åŠ 0.3ç§’çš„ç¼“å†²ï¼ˆè®©å­—å¹•å¤šåœç•™ä¸€ä¼šå„¿ï¼Œä¾¿äºé˜…è¯»ï¼‰
        end = end + 0.3
        
        # å¦‚æœæœ‰ä¸‹ä¸€ä¸ªå­—å¹•ï¼Œç¡®ä¿ä¸è¶…è¿‡ä¸‹ä¸€ä¸ªå­—å¹•çš„å¼€å§‹æ—¶é—´
        if i + 1 < len(segments):
            next_start = segments[i + 1]["start"]
            if end > next_start:
                # ç¼©çŸ­åˆ°ä¸‹ä¸€ä¸ªå­—å¹•å¼€å§‹å‰0.05ç§’ï¼ˆç•™ä¸€ç‚¹é—´éš™ï¼‰
                end = max(start + 0.5, next_start - 0.05)
        
        # ç¡®ä¿ç»“æŸæ—¶é—´æ™šäºå¼€å§‹æ—¶é—´
        if end <= start:
            text_chars = len([c for c in text if c.strip() and c not in 'ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼šã€,.!?;: ã€€ã€Œã€ã€ã€""''ï¼ˆï¼‰()ã€ã€‘[]'])
            estimated_duration = max(1.0, text_chars * 0.15)
            end = start + estimated_duration
        
        # ç¡®ä¿æœ€å°æ˜¾ç¤ºæ—¶é—´ï¼ˆè‡³å°‘0.5ç§’ï¼‰
        if end - start < 0.5:
            end = start + 0.5
            # å†æ¬¡æ£€æŸ¥æ˜¯å¦ä¸ä¸‹ä¸€ä¸ªå­—å¹•å†²çª
            if i + 1 < len(segments):
                next_start = segments[i + 1]["start"]
                if end > next_start:
                    end = max(start + 0.5, next_start - 0.05)
        
        fixed_segments.append({
            "start": start,
            "end": end,
            "text": text
        })
    
    # æ˜¾ç¤ºä¿®å¤ç»Ÿè®¡
    overlaps_fixed = sum(1 for i in range(len(segments)) if i > 0 and segments[i]["start"] < segments[i-1]["end"])
    if overlaps_fixed > 0:
        print(f"   ä¿®å¤äº† {overlaps_fixed} å¤„æ—¶é—´é‡å ")
    
    print(f"   ä¸ºæ¯ä¸ªå­—å¹•æ·»åŠ äº† 0.3ç§’ çš„é˜…è¯»ç¼“å†²æ—¶é—´")
    
    return fixed_segments
